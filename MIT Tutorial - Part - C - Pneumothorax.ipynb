{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumothorax example\n",
    "\n",
    "## Sentence tokenization, and spotting term + negation\n",
    "\n",
    "This example spots meantions of the \"pneumothorax\" lexicon in CXR reports and looks at whether the spotted pneumothorax mentioned was negated or not. \n",
    "\n",
    "*Joy Wu* <joy.wu@ibm.com>*, *Daniel Gruhl <dgruhl@us.ibm.com>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required files\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6451</td>\n",
       "      <td>183196.0</td>\n",
       "      <td>750185</td>\n",
       "      <td>[**2164-12-6**] 8:26 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23781</td>\n",
       "      <td>195460.0</td>\n",
       "      <td>745781</td>\n",
       "      <td>[**2165-9-28**] 2:50 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>738661</td>\n",
       "      <td>[**2153-1-12**] 10:03 PM\\n CHEST (PORTABLE AP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10118</td>\n",
       "      <td>146001.0</td>\n",
       "      <td>745821</td>\n",
       "      <td>[**2194-10-11**] 4:02 PM\\n CHEST (PORTABLE AP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13101</td>\n",
       "      <td>123718.0</td>\n",
       "      <td>740116</td>\n",
       "      <td>[**2123-8-22**] 9:46 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  row_id  \\\n",
       "0        6451  183196.0  750185   \n",
       "1       23781  195460.0  745781   \n",
       "2       24552       NaN  738661   \n",
       "3       10118  146001.0  745821   \n",
       "4       13101  123718.0  740116   \n",
       "\n",
       "                                                text  \n",
       "0  [**2164-12-6**] 8:26 PM\\n CHEST (PORTABLE AP) ...  \n",
       "1  [**2165-9-28**] 2:50 AM\\n CHEST (PORTABLE AP) ...  \n",
       "2  [**2153-1-12**] 10:03 PM\\n CHEST (PORTABLE AP)...  \n",
       "3  [**2194-10-11**] 4:02 PM\\n CHEST (PORTABLE AP)...  \n",
       "4  [**2123-8-22**] 9:46 AM\\n CHEST (PORTABLE AP) ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the sample CXR reports into a pandas dataframe, and print out a random report\n",
    "CXRreports = pd.read_csv('mimic3_1000cxrReports.csv')\n",
    "CXRreports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[**2194-1-23**] 4:13 PM\n",
      " CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 94843**]\n",
      " Reason: 29 yo wiht recent r. ij plecement-pulled rij out 2 cm-check\n",
      " ______________________________________________________________________________\n",
      " [**Hospital 3**] MEDICAL CONDITION:\n",
      "  29 year old man with\n",
      " REASON FOR THIS EXAMINATION:\n",
      "  29 yo wiht recent r. ij plecement-pulled rij out 2 cm-check for line placement\n",
      "  thank you\n",
      " ______________________________________________________________________________\n",
      "                                 FINAL REPORT\n",
      " PORTABLE CHEST: Compared to previous study of earlier the same date.\n",
      "\n",
      " INDICATION: Central line placement repositioning.\n",
      "\n",
      " A right internal jugular central venous catheter is present and terminates in\n",
      " the distal superior vena cava. An ETT is in satisfactory position and an NG\n",
      " tube is coiled in the stomach.\n",
      "\n",
      " Cardiac and mediastinal contours are stable. Bilateral asymmetric alveolar\n",
      " pattern affecting the left lung to a greater degree than the right is\n",
      " unchanged.\n",
      "\n",
      " There is probably a layering left pleural effusion.\n",
      "\n",
      " IMPRESSION: 1) Right internal jugular central venous catheter terminates in\n",
      " the distal superior vena cava. 2) Bilateral asymmetric alveolar pattern likely\n",
      " due to diffuse pneumonia and/or ARDS.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = CXRreports.text[random.randint(0,1000)]\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:\n",
      "[**2194-1-23**] 4:13 PM  CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 94843**]  Reason: 29 yo wiht recent r. ij plecement-pulled rij out 2 cm-check  ______________________________________________________________________________  [**Hospital 3**] MEDICAL CONDITION:   29 year old man with  REASON FOR THIS EXAMINATION:   29 yo wiht recent r. ij plecement-pulled rij out 2 cm-check for line placement   thank you  ______________________________________________________________________________                                  FINAL REPORT  PORTABLE CHEST: Compared to previous study of earlier the same date.\n",
      "\n",
      "Sentence 1:\n",
      "INDICATION: Central line placement repositioning.\n",
      "\n",
      "Sentence 2:\n",
      "A right internal jugular central venous catheter is present and terminates in  the distal superior vena cava.\n",
      "\n",
      "Sentence 3:\n",
      "An ETT is in satisfactory position and an NG  tube is coiled in the stomach.\n",
      "\n",
      "Sentence 4:\n",
      "Cardiac and mediastinal contours are stable.\n",
      "\n",
      "Sentence 5:\n",
      "Bilateral asymmetric alveolar  pattern affecting the left lung to a greater degree than the right is  unchanged.\n",
      "\n",
      "Sentence 6:\n",
      "There is probably a layering left pleural effusion.\n",
      "\n",
      "Sentence 7:\n",
      "IMPRESSION: 1) Right internal jugular central venous catheter terminates in  the distal superior vena cava.\n",
      "\n",
      "Sentence 8:\n",
      "2) Bilateral asymmetric alveolar pattern likely  due to diffuse pneumonia and/or ARDS.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the sentences with sent_tokenize from NLTK\n",
    "sents = sent_tokenize(report.replace('\\n',' ')) # removing new line breaks\n",
    "# Print out list of sentences:\n",
    "sent_count = 0\n",
    "for s in sents:\n",
    "    print(\"Sentence \" + str(sent_count) +\":\")\n",
    "    print(s)\n",
    "    print()\n",
    "    sent_count = sent_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: [0, 659]\n",
      "[**2194-1-23**] 4:13 PM  CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 94843**]  Reason: 29 yo wiht recent r. ij plecement-pulled rij out 2 cm-check  ______________________________________________________________________________  [**Hospital 3**] MEDICAL CONDITION:   29 year old man with  REASON FOR THIS EXAMINATION:   29 yo wiht recent r. ij plecement-pulled rij out 2 cm-check for line placement   thank you  ______________________________________________________________________________                                  FINAL REPORT  PORTABLE CHEST: Compared to previous study of earlier the same date.\n",
      "\n",
      "Sentence 1: [662, 711]\n",
      "INDICATION: Central line placement repositioning.\n",
      "\n",
      "Sentence 2: [714, 823]\n",
      "A right internal jugular central venous catheter is present and terminates in  the distal superior vena cava.\n",
      "\n",
      "Sentence 3: [824, 900]\n",
      "An ETT is in satisfactory position and an NG  tube is coiled in the stomach.\n",
      "\n",
      "Sentence 4: [903, 947]\n",
      "Cardiac and mediastinal contours are stable.\n",
      "\n",
      "Sentence 5: [948, 1060]\n",
      "Bilateral asymmetric alveolar  pattern affecting the left lung to a greater degree than the right is  unchanged.\n",
      "\n",
      "Sentence 6: [1063, 1114]\n",
      "There is probably a layering left pleural effusion.\n",
      "\n",
      "Sentence 7: [1117, 1224]\n",
      "IMPRESSION: 1) Right internal jugular central venous catheter terminates in  the distal superior vena cava.\n",
      "\n",
      "Sentence 8: [1225, 1311]\n",
      "2) Bilateral asymmetric alveolar pattern likely  due to diffuse pneumonia and/or ARDS.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "# Alternatively, tokenize with PunktSentenceTokenizer from NLTK if you want to keep track of character offsets of sentences\n",
    "sent_count = 0\n",
    "for s_start, s_finish in PunktSentenceTokenizer().span_tokenize(report):\n",
    "    print(\"Sentence \" + str(sent_count) +\": \" + str([s_start, s_finish]))\n",
    "    print(report[s_start:s_finish].replace('\\n',' '))\n",
    "    print()\n",
    "    sent_count = sent_count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot occurrence(s) of word(s) related to your concept in a sentence or document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple spotter: Spot occurrence of a term in a given lexicon anywhere within a text document or sentence:\n",
    "def spotter(text, lexicon):\n",
    "    text = text.lower()\n",
    "    # Spot if a document mentions any of the terms in the lexicon (not worrying about negation detection yet)\n",
    "    match = [x in text for x in lexicon]\n",
    "    if any(match) == True:\n",
    "        mentioned = 1\n",
    "    else:\n",
    "        mentioned = 0\n",
    "    return mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the lexicon is a list of word(s) or phrase(s) refering to a concept of interest to you, e.g.\n",
    "ptx = ['pneumothorax', 'ptx']\n",
    "sent1 = 'Large left apical ptx present.'\n",
    "sent2 = 'Hello world for NLP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lexicon mentioned in text, spotter return 1 (yes)\n",
    "spotter(sent1, ptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lexicon not mentioned in text, spotter return 0 (no)\n",
    "spotter(sent2, ptx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we do better?**\n",
    "We can do the spotting of concepts (lexicons) A LOT better (more sensitive) if we curate a list of all the ways that the concept could be expressed in raw text. This is what the NLP tool can help you achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a lexicon from the NLP tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "# Enter your team's username between the quotation marks:\n",
    "user = \"team1\"\n",
    "# Enter your team's password\n",
    "#password = getpass.getpass()\n",
    "# If the above doesn't work, then comment out the password variable above and hard code your team's password below:\n",
    "password = 'sends reforms capture mileage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the id of the lexicon - you can see it in the URL line when you are working with the lexicon\n",
    "# For example, for pneumothorax, it is:\n",
    "oid = \".2.48\"\n",
    "# You can do this in a loop to download all relevant lexicons into a data format you prefer too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't spam with insecure warnings - some machines do not have all signing authority\n",
    "# root certificates preinstalled\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The endpoints for the REST\n",
    "host = \"https://dla.sl.res.ibm.com\"\n",
    "lexurl = host + \"/oid\" + oid.replace('.', '/')\n",
    "quartermaster =  host + \"/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up auth and get the lexicon. Then pull the terms out and lower case them\n",
    "auth=(user,password)\n",
    "lex = requests.get(lexurl, verify=False, auth=auth).json()\n",
    "terms = list(map(lambda x: x[\"surfaceForm\"].lower(), lex[\"members\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pneumothorax', 'ptx', 'pneumothoraces', 'pnuemothorax', 'pnumothorax', 'pntx', 'penumothorax', 'pneomothorax', 'pneumonthorax', 'pnemothorax', 'pneumothoraxes', 'pneumpthorax', 'pneuomthorax', 'pneumothorx', 'pneumothrax', 'pneumothroax', 'pneumothraces', 'pneunothorax', 'enlarging pneumo', 'pneumothoroax', 'pneuothorax']\n"
     ]
    }
   ],
   "source": [
    "# Printing out the pneumothorax lexicon (after 5 minutes of curating work on the NLP tool)\n",
    "ptx = terms.copy()\n",
    "print(ptx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But it's not enough to just spot word occurrences to determine if a concept is affirmative (positive/present) or not.\n",
    "\n",
    "# e.g. lexicon mentioned in text but negated, a simple spotter would still return 1 (yes)\n",
    "sent3 = 'Pneumothorax has resolved.'\n",
    "spotter(sent3, ptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However, if negation related words occur in close proximity (e.g. same sentence) to a spotted concept \n",
    "# Then we can right some rules to determine if the concept was negated or not\n",
    "\n",
    "# e.g. spotting negation words in the same sentence:\n",
    "neg = ['no','never','not','removed', 'ruled out']\n",
    "spotter(sent2, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using off-the-shelf python library for negation, e.g. Negex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negated'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import negex\n",
    "rfile = open(r'negex_triggers.txt')\n",
    "irules = negex.sortRules(rfile.readlines())\n",
    "rfile.close()\n",
    "\n",
    "# Example:\n",
    "sent = \"There is no evidence of ptx.\"\n",
    "#ptx = ['pneumothorax', 'ptx']\n",
    "tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
    "negation = tagger.getNegationFlag()\n",
    "negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:\n",
      "There is no focal  consolidation, pleural effusion, or pneumothorax.\n",
      "Negex output: negated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Negex to the first note:\n",
    "# Specify the lexicon of interest (\"phrases\" for Negex)\n",
    "ptx = terms.copy()\n",
    "# Get a randome note from the dataset:\n",
    "note = CXRreports['text'][random.randint(0,1000)]\n",
    "# Tokenize the sentences:\n",
    "sents = sent_tokenize(note.replace('\\n',' ')) # replacing new line breaks\n",
    "# Applying spotter function to each sentence:\n",
    "#neg_output = []\n",
    "count = 0\n",
    "for sent in sents:\n",
    "    # Apply Negex if a term in the ptx lexicon is spotted\n",
    "    if spotter(sent,ptx) == 1:\n",
    "        tagger = negex.negTagger(sentence = sent, phrases = ptx, rules = irules, negP=False)\n",
    "        negation = tagger.getNegationFlag()\n",
    "        #neg_output.append(negation)\n",
    "        print(\"Sentence \" + str(count) + \":\\n\" + sent + \"\\nNegex output: \" + negation + '\\n')\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[**2100-7-17**] 7:22 AM\n",
      " CHEST (PORTABLE AP)                                             Clip # [**Clip Number (Radiology) 70021**]\n",
      " Reason: pt with acidosis hx chf\n",
      " ______________________________________________________________________________\n",
      " [**Hospital 2**] MEDICAL CONDITION:\n",
      "  74 year old man with ERSD, CAD, PVD, DM s/p AKA w/ worsening acidosis, rales\n",
      " REASON FOR THIS EXAMINATION:\n",
      "  pt with acidosis hx chf\n",
      " ______________________________________________________________________________\n",
      "                                 FINAL REPORT\n",
      " INDICATION:  Worsening acidosis and rales.\n",
      "\n",
      " COMPARISONS:  [**2100-7-16**]\n",
      "\n",
      " PORTABLE AP CHEST:  The left internal jugular central venous catheter tip is\n",
      " in the left brachiocephalic vein. The cardiomediastinal silhouette is stable.\n",
      " There are multiple bilateral calcified pleural plaques. There is no focal\n",
      " consolidation, pleural effusion, or pneumothorax.  Allowing for differences in\n",
      " technique and positioning, there has been no significant change.\n",
      "\n",
      " IMPRESSION:\n",
      " 1. Bilateral calcified pleural plaques representing asbestos related pleural\n",
      " disease.\n",
      " 2. No CHF.\n",
      " 3. No significant interval change.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the relevant CXR report for the analysis\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for you:\n",
    "\n",
    "You can use similar/improved pipeline to loop through all the notes in your dataset and through different concepts/lexicons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
